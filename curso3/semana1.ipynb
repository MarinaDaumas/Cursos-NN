{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semana 1: ML Strategy 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why ML Strategy\n",
    "\n",
    "Supose you are training a network and now have a 90% accuracy but you need an even higher accuracy. There are many things you can think of doing.\n",
    "\n",
    "- Collect more data\n",
    "- Colect more diverse training set\n",
    "- Train longer with gradient descent\n",
    "- Try Adam instead of gradient descent\n",
    "- Try bigger/smaller network\n",
    "- Try dropout\n",
    "- Add L_2 regulatization \n",
    "- Change network architecture\n",
    "    \n",
    "    - activation\n",
    "    - #hidden units\n",
    "    - etc.\n",
    "    \n",
    "There are many options, wich make it easy to waste lot of time trying things that in the end are not going to help very much. This couse teaches strategies that help analysing the problem to choose the most promissing things to try. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonalization\n",
    "\n",
    "If you have a cotrol syste that is orthogonal, this means that each one of the controllers affect only one of the parameters or dimenisons of you problem. In a car, for exemple, there's the steering wheel that controls the angle and aceleration and break to control the speed. This is orthogonal control. \n",
    "\n",
    "If it wasn't orthogonal it would something like 3 steerings that each controled for example 0.5 of the angle and 0.2 of the speed, 0.9 of the angle and 1.5 of speed and 0.3 of angle and 0.8 of speed. It could be possible to control but very difficult. \n",
    "\n",
    "That's why we want to control the performance of our netkwork orthogonaly. We will analize how the network is performing on training, dev and test sets and how it's performing on real life separately and tune these separetely. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single number evaluation metric\n",
    "\n",
    "It's easier to compare different versions of a netwrok if you have one number to compare only. So if you have, for exemple a cat classifier and you have the precision and recall of each version of the network you should calculate something like the F1 score ($F1 = \\frac{2}{1/precision + 1/recall}$) and compare this number. Or if your classifier is used in different types of images calculate the average of the error in each type of image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satisficing and optimizing\n",
    "\n",
    "Sometimes it is hard to combine all things we want to evaluate in one single metric. If you want to compare the accuracy (F1 score or some ohter measure) and running time you can calculate somenthing like accuracy $- 0.5*$ runnig time but it is not good. So we separate the params between satisficing and optimizing.\n",
    "\n",
    "- Satisficing param just needs to be in a specific treshold.\n",
    "\n",
    "- Optimizing param is the one you will compare to chose the better.\n",
    "\n",
    "COLOCAR TABELA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting train, dev and test sets\n",
    "\n",
    "Dev an Test set should come from same distribution. When you train comparing to the dev set is like trainig to reach target. If the test data is too diffent from dev data, qhen testing on the test set will be like trying to hit a target aiming at another.\n",
    "\n",
    "Size of dev and test is important too. \n",
    "\n",
    "- Old rule of thumb (useful for \"small\" amount of data) \n",
    "\n",
    "    70% train and 30% test or\n",
    "    \n",
    "    60% train, , 20% dev and 20% test \n",
    "    \n",
    "    \n",
    "- Nowadays rule\n",
    "\n",
    "    The number of exemples in dev and test sets may be much less than 20% in the era of big data. If you have something like 1.000.000 exemples in your data 1% of it for dev set might be more than enough. The number of exemples should be only enough to give you the confidence that your network is accurate  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sometimes you don't need a test set. When there's only train and test set, the 'test' set is actually a dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
